---
layout: about
title: about
permalink: /
subtitle: <span style='color:grey'>Computer Science Ph.D. student @ <a href='https://cs.brown.edu/' style='color:#222222'>Brown University</a><br>Research Scientist Intern @ <a href='https://ai.meta.com/' style='color:#222222'>Meta AI (FAIR)</a>, Collaborator @ <a href='https://cohere.com/research' style='color:#222222'>Cohere For AI</a></span>

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: 

news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

I am a rising fourth-year Ph.D. student in Computer Science at Brown University, advised by [Prof. Stephen Bach](https://cs.brown.edu/people/sbach/). I'm fortunate to have collaborated with amazing researchers at [Cohere For AI](https://cohere.com/research) and at [Meta AI (FAIR and GenAI Trust Team)](https://ai.meta.com/).

**Lately, I work on making multilingual LLMs safe.** 
- I was the first to reveal cross-lingual safety vulnerability [(NeurIPS 2023 Socially Responsible Language Modeling Workshop, &#11089;Best Paper Award)](https://arxiv.org/abs/2310.02446) by discovering that GPT-4 can be jailbroken when malicious instructions are translated into low-resource languages. Our work was cited by the UK Government and AI Safety Institute in the [International Scientific Report on the Safety of Advanced AI 2024](https://www.gov.uk/government/publications/international-scientific-report-on-the-safety-of-advanced-ai) to highlight the need for multilingual red-teaming.
- I collaborated with Cohere For AI to perform multilingual safety red-teaming for Aya-101 [(ACL 2024, &#11089;Best Paper Award)](https://arxiv.org/abs/2402.07827), which is the state-of-the-art LLM that follows instructions in 101 languages.
- I researched cross-lingual transfer of safety knowledge, such as toxicity [(Findings of EMNLP 2024)](https://arxiv.org/abs/2406.16235) and harmful-finetuning (coming soon).

I also dedicate efforts to **create intelligent systems that overcome language barriers** and serve all users around the world, including those who speak underrepresented languages, through model-centric and data-centric solutions.
- I researched how to finetune multilingual LLMs, such as BLOOM+1 [(ACL 2023)](https://arxiv.org/abs/2212.09535), to adapt to low-resource languages unseen during pretraining.
- I proposed novel methods to generate synthetic training data for underrepresented languages. For the very first time, synthetic data generated by our proposed LexC-Gen [(Findings of EMNLP 2024)](https://arxiv.org/abs/2402.14086) can match the performance of manually collected training data for very low-resource languages in Indonesia and Africa.
- I helped build massively multilingual foundational models (including LLMs and speech models):
  - **[Meta AI (FAIR)](https://ai.meta.com/research/)**: I worked on mitigating accent bias for the [Massively Multilingual Speech model](https://about.fb.com/news/2023/05/ai-massively-multilingual-speech-technology/).
  - **[Cohere For AI](https://cohere.com/research/aya)**: I served as [language ambassador](https://cohere.com/research/aya-contributors-test) who coordinate the data collection efforts for Malay language in [Aya dataset](https://arxiv.org/abs/2402.06619). In addition, I was part of safety red-teaming team for Aya models.
  - **[BigScience](https://bigscience.huggingface.co/)**: I contributed to LLMs such as [BLOOM](https://arxiv.org/abs/2211.05100), [T0](https://arxiv.org/abs/2110.08207) and [mT0/BLOOMZ](https://arxiv.org/abs/2211.01786). In addition, I led the research efforts for adapting BLOOM to unseen languages.
  
As a Malaysian, I also contributed to **NLP for Southeast Asian (SEA) languages** outside my PhD. I've hosted [*ACL tutorials](https://aclanthology.org/2023.ijcnlp-tutorials.2/), helped curate SEACrowd data hub [(EMNLP 2024)](https://arxiv.org/abs/2406.10118), and studied how well LLMs can handle SEA linguistic phenomenon, such as code-switching [(EMNLP 2023 CALCS Workshop)](https://arxiv.org/abs/2303.13592), and understand culture in SEA region [(NeurIPS 2024)](https://arxiv.org/abs/2406.05967).

**Other Misc Stuff:**
- If you want to chat or collaborate, you can reach me here: `contact [dot] yong @ brown [dot] edu`. 
- I love salsa dancing, and I'm learning bachata moderna. I also dance a bit of Lindy Hop, Argentine Tango and K-pop. <br>I usually check out the dance scenes in the city when I travel to conferences â€“ if you see this and want to go dance together, hmu.
- I went to [Minerva University](https://www.minerva.edu/) during undergrad so I had the opportunity to travel and live in six different cities around the world: San Francisco, Seoul, Hyderabad, Berlin Buenos Aires and London. 