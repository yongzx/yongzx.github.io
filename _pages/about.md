---
layout: about
title: about
permalink: /
subtitle: <span style='color:grey'>Computer Science Ph.D. student @ <a href='https://cs.brown.edu/' style='color:#222222'>Brown University</a><br>Research Scientist Intern @ <a href='https://ai.meta.com/' style='color:#222222'>Meta AI (FAIR)</a>, Collaborator @ <a href='https://cohere.com/research' style='color:#222222'>Cohere For AI</a></span>

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: 

news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

I am a rising fourth-year Ph.D. student in Computer Science at Brown University. I am fortunate to be advised by [Prof. Stephen Bach](https://cs.brown.edu/people/sbach/). I occasionally blog on [Substack](https://newsletter.yongzx.io/). 

**Industry Experience:** Currently, I am a research scientist intern at [Meta AI (FAIR)](https://ai.meta.com/research/) under the supervision of [Jean Maillard](https://maillard.it/), working on red-teaming for [Massively Multilingual Speech (MMS)](https://ai.meta.com/blog/multilingual-model-speech-recognition/) models. Previously, I worked on multilingual safety at [Cohere For AI (Aya)](https://cohere.com/research/aya) and low-resource language adapation at [BigScience](https://bigscience.huggingface.co/). 

**Research Interests:** I work on *multilingual, safe, and inclusive AI* as I believe that intelligent systems should serve everyone across the world.
1. ***multilingual safety*** – My [discovery that GPT-4 can be jailbroken by low-resource languages](https://arxiv.org/abs/2310.02446) highlights the need for multilingual red-teaming. I also study when safety knowledge can transfer cross-lingually using mechanistic tools (e.g., [detoxification](https://arxiv.org/abs/2406.16235)). I also worked on multilingual red-teaming for frontier AI systems at Meta AI (MMS models) and [Cohere For AI (Aya models)](https://arxiv.org/abs/2402.07827).

2. ***building open-source multilingual LLMs*** – I am a major contributor to the open-source ecosystem of frontier multilingual LLMs. For instance, I served as [Aya Malay language ambassador](https://cohere.com/research/aya-contributors-test) in addition to [safety red-teaming](https://arxiv.org/abs/2402.07827) for Aya models at [Cohere For AI](https://cohere.com/research). I also contributed to [BLOOM](https://arxiv.org/abs/2211.05100), [T0](https://arxiv.org/abs/2110.08207) and [mT0/BLOOMZ](https://arxiv.org/abs/2211.01786) at [BigScience](https://bigscience.huggingface.co/). In addition, I led the research for [adapting BLOOM to unseen languages](https://arxiv.org/abs/2212.09535) at BigScience.

3. ***enabling AI to serve underrepresented populations*** – Frontier AI systems these days only cater to first-class citizen languages. To bridge the language gap in AI, I worked on [language adaptation of LLMs to low-resource languages](https://arxiv.org/abs/2212.09535). I also dedicate NLP efforts for *South-East-Asian (SEA) languages*. I helped curate [SEACrowd data hub](https://arxiv.org/abs/2406.10118) and evaluate how well LLMs handle common SEA linguistic phenomena such as [code-switching](https://arxiv.org/abs/2303.13592).