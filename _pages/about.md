---
layout: about
title: about
permalink: /
subtitle: Computer Science Ph.D. student @ <a href='https://cs.brown.edu/'>Brown University</a><br>Research Scientist Intern @ <a href='https://ai.meta.com/'>Meta AI (FAIR)</a>

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: 

news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

I am a rising fourth-year Ph.D. student in Computer Science at Brown University. I am fortunate to be advised by [Prof. Stephen Bach](https://cs.brown.edu/people/sbach/). Currently, I am a research scientist intern at [Meta AI (FAIR)](https://ai.meta.com/research/) under the supervision of [Jean Maillard](https://maillard.it/). 
<!-- My research interests are centered around **multilingual, inclusive, and safe foundational models**.  -->

<!-- Prior to joining Ph.D., I obtained a B.Sc. in Computer Science from [Minerva University](https://www.minerva.edu/), and I worked with linguists [Prof. Tiago Torrent](https://www.tiagotorrent.com/), [Prof. Oliver Czulo](https://home.uni-leipzig.de/czulo/), and [Collin F. Baker](https://www.icsi.berkeley.edu/icsi/people/collinb) on frame semantics during my undergrad. -->

Outside of PhD, I actively contribute to open-source multilingual LLMs initiative (e.g., [BigScience](https://bigscience.huggingface.co/), [Aya](https://cohere.com/blog/aya-multilingual)) and NLP development for South-East Asian (SEA) languages. I also occasionally blog on [Substack](https://newsletter.yongzx.io/). 

**I believe that intelligent systems should be multilingual, safe, and inclusive**. To this end, I work on following research directions:
1. **<span style="color:brown">making frontier AI safer for all language users</span>** – My [discovery that low-resource languages can jailbreak GPT-4](https://arxiv.org/abs/2310.02446) pioneered and raised awareness for multilingual red-teaming. Since then, I work on responsible AI research for *multilingual foundational models*.
 - I was part of the Responsible Release team for [Aya-101](https://arxiv.org/abs/2402.07827) (SOTA fully open-source LLM from 2024--now) at Cohere For AI.
 - I currently work on bias mitigation for [Massively Multilingual Speech (MMS)](https://arxiv.org/abs/2305.13516) models at Meta AI. 

2. **<span style="color:brown">building open-source multilingual LMs</span>** – I've contributed to the earliest English and multilingual instruction-following LLMs, such as [T0](https://arxiv.org/abs/2110.08207) (with [PromptSource](https://arxiv.org/abs/2202.01279)) and [mT0/BLOOMZ](https://arxiv.org/abs/2211.01786). I was also involved in the [development](https://arxiv.org/abs/2211.05100) and [evaluation](https://arxiv.org/abs/2210.15424) of BLOOM model at [BigScience](https://bigscience.huggingface.co/), and I helped collect Malay instruction-following data (as [Aya language ambassador](https://cohere.com/research/aya-contributors-test)) and perform [safety evaluation](https://arxiv.org/abs/2402.07827) for the Aya-101 model.
3. **<span style="color:brown">enabling AI to serve underrepresented populations</span>** – Frontier AI systems these days only cater to first-class citizen languages, leaving many communities across the world left unsupported. To support underrepresented languages, I led language adaption research at BigScience to [efficiently adapt BLOOM to languages unseen during training](https://arxiv.org/abs/2212.09535).
<!-- and [designed synthetic data generation method for extremely low-resource languages](https://arxiv.org/abs/2402.14086).  -->
I also worked on developing NLP systems for South-East-Asian (SEA) languages such as Tamil and Tagalog by curating [SEACrowd benchmark](https://arxiv.org/abs/2406.10118) and showing [how poorly multilingual LLMs code-switch in SEA languages](https://arxiv.org/abs/2303.13592).