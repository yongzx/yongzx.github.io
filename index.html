<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="hFGM4TxPxthFmk31fTMEoGDKPU69WmAzgBZsOC0bzAk"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Yong Zheng-Xin </title> <meta name="author" content="Yong Zheng-Xin"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%91%A8%E2%80%8D%F0%9F%92%BB&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://yongzx.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%63%6F%6E%74%61%63%74.%79%6F%6E%67@%62%72%6F%77%6E.%65%64%75" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=z6bOk-AAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://www.linkedin.com/in/yongzx" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://twitter.com/yong_zhengxin" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> <a href="https://yongzx.github.io/blog/" title="Blogger"><i class="fa-brands fa-blogger-b"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item"><a class="nav-link" href="/assets/pdf/cv_yong_aug24.pdf">cv</a></li> <li class="nav-item"><a class="nav-link" href="https://yongzx.github.io/blog">blog</a></li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Yong</span> Zheng-Xin </h1> <p class="desc"><span style="color:grey">Computer Science Ph.D. student @ <a href="https://cs.brown.edu/" style="color:#222222" rel="external nofollow noopener" target="_blank">Brown University</a><br>Research Scientist Intern @ <a href="https://ai.meta.com/" style="color:#222222" rel="external nofollow noopener" target="_blank">Meta AI (FAIR)</a>, Collaborator @ <a href="https://cohere.com/research" style="color:#222222" rel="external nofollow noopener" target="_blank">Cohere For AI</a></span></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/prof_pic.jpg?a7550ca4e65c099866f3b23543cf5fc0" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic.jpg" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <p>I am a rising fourth-year Ph.D. student in Computer Science at Brown University. I am fortunate to be advised by <span style="color: black !important; "><a href="https://cs.brown.edu/people/sbach/" rel="external nofollow noopener" target="_blank">Prof. Stephen Bach</a></span>. I work on making AI <strong>safe and inclusive</strong>.</p> <p><strong>Industry Experience:</strong> Currently, I am a research scientist intern at Meta AI (FAIR) under the supervision of <a href="https://maillard.it/" rel="external nofollow noopener" target="_blank">Jean Maillard</a>, working on multimodal safety and robustness research. Previously, I worked on multilingual safety at Cohere For AI <a href="https://cohere.com/research/aya" rel="external nofollow noopener" target="_blank">(Aya)</a> and low-resource language adapation at <a href="https://bigscience.huggingface.co/" rel="external nofollow noopener" target="_blank">BigScience</a>.</p> <p><strong>Research Interests:</strong> I think broadly about how we can create intelligent systems that are accessible to global users without causing harm. So far, I work along these directions:</p> <ol> <li> <p><strong><em>multilingual safety</em></strong> – My <a href="https://arxiv.org/abs/2310.02446" rel="external nofollow noopener" target="_blank">discovery that GPT-4 can be jailbroken by low-resource languages</a> highlights the need for multilingual red-teaming. I also study how safety knowledge (e.g., <a href="https://arxiv.org/abs/2406.16235" rel="external nofollow noopener" target="_blank">detoxification</a>) can transfer cross-lingually using mechanistic tools. In addition, I collaborate with frontier labs. I worked on <a href="https://arxiv.org/abs/2402.07827" rel="external nofollow noopener" target="_blank">multilingual red-teaming for Aya-101</a> at Cohere For AI, and now I work on safety for multilingual speech models at Meta AI.</p> </li> <li> <p><strong><em>building open-source multilingual LLMs</em></strong> – I have been a major contributor to the open-source multilingual LLMs ecosystem. For instance, I served as <a href="https://cohere.com/research/aya-contributors-test" rel="external nofollow noopener" target="_blank">Aya Malay language ambassador</a> in addition to <a href="https://arxiv.org/abs/2402.07827" rel="external nofollow noopener" target="_blank">safety red-teaming</a> for Aya models at <a href="https://cohere.com/research" rel="external nofollow noopener" target="_blank">Cohere For AI</a>. I also contributed to <a href="https://arxiv.org/abs/2211.05100" rel="external nofollow noopener" target="_blank">BLOOM</a>, <a href="https://arxiv.org/abs/2110.08207" rel="external nofollow noopener" target="_blank">T0</a> and <a href="https://arxiv.org/abs/2211.01786" rel="external nofollow noopener" target="_blank">mT0/BLOOMZ</a> at <a href="https://bigscience.huggingface.co/" rel="external nofollow noopener" target="_blank">BigScience</a>. In addition, I led the research for <a href="https://arxiv.org/abs/2212.09535" rel="external nofollow noopener" target="_blank">adapting BLOOM to unseen languages</a> at BigScience.</p> </li> <li> <p><strong><em>enabling AI to serve underrepresented populations</em></strong> – To bridge the language gap in AI, I work on model-centric (<a href="https://arxiv.org/abs/2212.09535" rel="external nofollow noopener" target="_blank">language adaptation</a>) and data-centric (<a href="https://arxiv.org/abs/2402.14086" rel="external nofollow noopener" target="_blank">synthetic data generation</a>) solutions. My <a href="https://arxiv.org/abs/2402.14086" rel="external nofollow noopener" target="_blank">most recent work</a> generated synthetic data that can match against manually-collected labeled data for the very first time in low-resource languages. I also dedicate NLP efforts for <em>South-East-Asian (SEA) languages</em>. I helped curate <a href="https://arxiv.org/abs/2406.10118" rel="external nofollow noopener" target="_blank">SEACrowd data hub</a> and evaluate how well LLMs handle common SEA linguistic phenomena such as <a href="https://arxiv.org/abs/2303.13592" rel="external nofollow noopener" target="_blank">code-switching</a>.</p> </li> </ol> <p>I love collaborations. If you want to chat or collaborate, you can reach me here: <code class="language-plaintext highlighter-rouge">contact [dot] yong @ brown [dot] edu</code>. I also occasionally write on my <a href="https://yongzx.github.io/blog">blog</a>.</p> </div> <h2> selected recent publications (<a href="/publications/" style="color: inherit">see all</a>) </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div id="li2024preference" class="col-sm-11"> <div class="title">Preference Tuning For Toxicity Mitigation Generalizes Across Languages</div> <div class="author"> Xiaochen Li* ,  <em>Zheng-Xin Yong*</em> ,  and  Stephen H Bach </div> <div class="periodical"> <em>arXiv</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2406.16235" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/BatsResearch/cross-lingual-detox" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Detoxifying multilingual Large Language Models (LLMs) has become crucial due to their increasing global use. In this work, we explore zero-shot cross-lingual generalization of preference tuning in detoxifying LLMs. Unlike previous studies that show limited cross-lingual generalization for other safety tasks, we demonstrate that Direct Preference Optimization (DPO) training with only English data can significantly reduce toxicity in multilingual open-ended generations. For example, the probability of mGPT-1.3B generating toxic continuations drops from 46.8% to 3.9% across 17 different languages after training. Our results also extend to other multilingual LLMs, such as BLOOM, Llama3, and Aya-23. Using mechanistic interpretability tools like causal intervention and activation analysis, we identified the dual multilinguality property of MLP layers in LLMs, which explains the cross-lingual generalization of DPO. Finally, we show that bilingual sentence retrieval can predict the cross-lingual transferability of DPO preference tuning.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="ustun2024aya" class="col-sm-11"> <div class="title">Aya model: An instruction finetuned open-access multilingual language model</div> <div class="author"> Ahmet Üstün* ,  Viraat Aryabumi* ,  <em>Zheng-Xin Yong*</em> , and <span class="more-authors" title="click to view 14 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '14 more authors' ? 'Wei-Yin Ko*, Daniel D’souza*, Gbemileke Onilude, Neel Bhandari, Shivalika Singh, Hui-Lee Ooi, Amr Kayid, Freddie Vargus, Phil Blunsom, Shayne Longpre, Niklas Muennighoff, Marzieh Fadaee, Julia Kreutzer, Sara Hooker' : '14 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">14 more authors</span> </div> <div class="periodical"> <em>ACL</em>, 2024 </div> <div class="periodical"> </div> <div class="title"> <span style="color:brown; font-weight:bold">Best Paper Award</span> </div> <div class="title"> <span style="font-weight:bold"> Also featured in: </span> <a href="https://www.washingtonpost.com/politics/2024/02/13/ftcs-bedoya-says-laws-keep-teens-off-social-media-wont-work" rel="external nofollow noopener" target="_blank">The Washington Post</a> , <a href="https://www.theglobeandmail.com/business/article-ai-chatbots-fall-short-in-dozens-of-languages-a-non-profit-project" rel="external nofollow noopener" target="_blank">The Globe and Mail</a> , <a href="https://siliconangle.com/2024/02/13/cohere-ai-unveils-aya-multilingual-open-source-ai-101-languages/" rel="external nofollow noopener" target="_blank">SiliconANGLE</a> and many more </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2402.07827" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Recent breakthroughs in large language models (LLMs) have centered around a handful of data-rich languages. What does it take to broaden access to breakthroughs beyond first-class citizen languages? Our work introduces Aya, a massively multilingual generative language model that follows instructions in 101 languages of which over 50% are considered as lower-resourced. Aya outperforms mT0 and BLOOMZ on the majority of tasks while covering double the number of languages. We introduce extensive new evaluation suites that broaden the state-of-art for multilingual eval across 99 languages – including discriminative and generative tasks, human evaluation, and simulated win rates that cover both held-out tasks and in-distribution performance. Furthermore, we conduct detailed investigations on the optimal finetuning mixture composition, data pruning, as well as the toxicity, bias, and safety of our models.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="yong2023lowresource" class="col-sm-11"> <div class="title">Low-Resource Languages Jailbreak GPT-4</div> <div class="author"> <em>Zheng-Xin Yong</em> ,  Cristina Menghini ,  and  Stephen Bach </div> <div class="periodical"> <em>In NeurIPS Workshop: Socially Responsible Language Modelling Research (SoLaR)</em> , 2023 </div> <div class="periodical"> </div> <div class="title"> <span style="color:brown; font-weight:bold">Best Paper Award</span> </div> <div class="title"> <span style="font-weight:bold"> Also featured in: </span> <a href="https://www.newscientist.com/article/2398656-gpt-4-gave-advice-on-planning-terrorist-attacks-when-asked-in-zulu/" rel="external nofollow noopener" target="_blank">New Scientist</a> , <a href="https://hal.science/hal-04612963/document" rel="external nofollow noopener" target="_blank">UK AI Safety Institute (Scientific Report)</a> , <a href="https://www.zdnet.com/article/the-safety-of-openais-gpt-4-is-lost-in-translation/" rel="external nofollow noopener" target="_blank">ZDNet</a> and many more </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2310.02446" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>AI safety training and red-teaming of large language models (LLMs) are measures to mitigate the generation of unsafe content. Our work exposes the inherent cross-lingual vulnerability of these safety mechanisms, resulting from the linguistic inequality of safety training data, by successfully circumventing GPT-4’s safeguard through translating unsafe English inputs into low-resource languages. On the AdvBenchmark, GPT-4 engages with the unsafe translated inputs and provides actionable items that can get the users towards their harmful goals 79% of the time, which is on par with or even surpassing state-of-the-art jailbreaking attacks. Other high-/mid-resource languages have significantly lower attack success rate, which suggests that the cross-lingual vulnerability mainly applies to low-resource languages. Previously, limited training on low-resource languages primarily affects speakers of those languages, causing technological disparities. However, our work highlights a crucial shift: this deficiency now poses a risk to all LLMs users. Publicly available translation APIs enable anyone to exploit LLMs’ safety vulnerabilities. Therefore, our work calls for a more holistic red-teaming efforts to develop robust multilingual safeguards with wide language coverage.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="yong-etal-2023-prompting" class="col-sm-11"> <div class="title">Prompting Multilingual Large Language Models to Generate Code-Mixed Texts: The Case of South East Asian Languages</div> <div class="author"> <em>Zheng-Xin Yong</em> ,  Ruochen Zhang ,  Jessica Forde , and <span class="more-authors" title="click to view 13 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '13 more authors' ? 'Skyler Wang, Arjun Subramonian, Holy Lovenia, Samuel Cahyawijaya, Genta Winata, Lintang Sutawika, Jan Christian Blaise Cruz, Yin Lin Tan, Long Phan, Long Phan, Rowena Garcia, Thamar Solorio, Alham Fikri Aji' : '13 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">13 more authors</span> </div> <div class="periodical"> <em>In EMNLP Workshop: Computational Approaches to Linguistic Code-Switching (CALCS)</em> , 2023 </div> <div class="periodical"> </div> <div class="title"> <span style="font-weight:bold"> Also featured in: </span> <a href="https://www.wired.com/story/chatgpt-non-english-languages-ai-revolution/" rel="external nofollow noopener" target="_blank">WIRED</a> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2023.calcs-1.5.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/Southeast-Asia-NLP/LLM-Code-Mixing" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>The differences in decision making between behavioural models of voice interfaces are hard to capture using existing measures for the absolute performance of such models. For instance, two models may have a similar task success rate, but very different ways of getting there. In this paper, we propose a general methodology to compute the similarity of two dialogue behaviour models and investigate different ways of computing scores on both the semantic and the textual level. Complementing absolute measures of performance, we test our scores on three different tasks and show the practical usability of the measures.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="yong-etal-2023-bloom" class="col-sm-11"> <div class="title">BLOOM+1: Adding Language Support to BLOOM for Zero-Shot Prompting</div> <div class="author"> <em>Zheng-Xin Yong</em> ,  Hailey Schoelkopf ,  Niklas Muennighoff , and <span class="more-authors" title="click to view 12 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '12 more authors' ? 'Alham Fikri Aji, David Ifeoluwa Adelani, Khalid Almubarak, M Saiful Bari, Lintang Sutawika, Jungo Kasai, Ahmed Baruwa, Genta Winata, Stella Biderman, Edward Raff, Dragomir Radev, Vassilina Nikoulina' : '12 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">12 more authors</span> </div> <div class="periodical"> <em>In ACL</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2023.acl-long.653.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/bigscience-workshop/multilingual-modeling" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>The BLOOM model is a large publicly available multilingual language model, but its pretraining was limited to 46 languages. To extend the benefits of BLOOM to other languages without incurring prohibitively large costs, it is desirable to adapt BLOOM to new languages not seen during pretraining. In this work, we apply existing language adaptation strategies to BLOOM and benchmark its zero-shot prompting performance on eight new languages in a resource-constrained setting. We find language adaptation to be effective at improving zero-shot performance in new languages. Surprisingly, we find that adapter-based finetuning is more effective than continued pretraining for large models. In addition, we discover that prompting performance is not significantly affected by language specifics, such as the writing system. It is primarily determined by the size of the language adaptation data. We also add new languages to BLOOMZ, which is a multitask finetuned version of BLOOM capable of following task instructions zero-shot. We find including a new language in the multitask fine-tuning mixture to be the most effective method to teach BLOOMZ a new language. We conclude that with sufficient training data language adaptation can generalize well to diverse languages. Our code is available at \urlhttps://github.com/bigscience-workshop/multilingual-modeling.</p> </div> </div> </div> </li> </ol> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%"><span style="color:black">2024 (Jul)</span></th> <td> <span style="color:black">🎙️ Presented my work on multilingual AI safety at <a href="https://lu.ma/fl2t9xms" rel="external nofollow noopener" target="_blank">London Data Week</a>. </span> </td> </tr> <tr> <th scope="row" style="width: 20%"><span style="color:black">2024 (Jun)</span></th> <td> <span style="color:black">➡️ <strong>Meta AI</strong>: Started my research scientist internship at Meta AI (FAIR). Will be red-teaming the <a href="https://ai.meta.com/blog/multilingual-model-speech-recognition/" rel="external nofollow noopener" target="_blank">Massively Multilingual Speech (MMS)</a> models. </span> </td> </tr> <tr> <th scope="row" style="width: 20%"><span style="color:black">2024 (Feb)</span></th> <td> <span style="color:black">🔥 <strong><a href="https://cohere.com/research/aya" rel="external nofollow noopener" target="_blank">Aya</a></strong> model and dataset papers are released! I presented Aya multilingual safety research at Aya Grand Finale. <a href="https://arxiv.org/abs/2402.07827" rel="external nofollow noopener" target="_blank">Aya model paper</a> (where I was a co-first author) received the <strong>⭑ACL 2024 best paper award</strong>. </span> </td> </tr> <tr> <th scope="row" style="width: 20%"><span style="color:black">2023 (Nov)</span></th> <td> <span style="color:black">🎙️ Co-organized and gave the tutorial of <a href="https://aacl2023-sea-nlp.github.io/" rel="external nofollow noopener" target="_blank">Current Status of NLP in South East Asia</a> at AACL’23. </span> </td> </tr> <tr> <th scope="row" style="width: 20%"><span style="color:black">2023 (Oct)</span></th> <td> <span style="color:black">🔥 “<strong><a href="https://arxiv.org/abs/2310.02446" rel="external nofollow noopener" target="_blank">Low-Resource Languages Jailbreak GPT-4</a></strong>” was accepted as the <strong>⭑ best paper</strong> at NeurIPS Socially Responsible Language Modeling (SoLaR) workshop. Also interviewed by <a href="https://www.newscientist.com/article/2398656-gpt-4-gave-advice-on-planning-terrorist-attacks-when-asked-in-zulu/" rel="external nofollow noopener" target="_blank">New Scientist</a> and featured on other media. </span> </td> </tr> <tr> <th scope="row" style="width: 20%"><span style="color:black">2023 (Sep)</span></th> <td> <span style="color:black">➡️ <strong>Cohere For AI</strong>: Joining the Responsible Deployment Team for red-teaming <a href="https://sites.google.com/cohere.com/aya-en/home" rel="external nofollow noopener" target="_blank">Aya</a> multilingual LLMs. </span> </td> </tr> <tr> <th scope="row" style="width: 20%"><span style="color:black">2023 (Aug)</span></th> <td> <span style="color:black">🪑 First time serving as the Area Chair (Multilingualism &amp; Linguistic Diversity Track in <a href="https://2023.emnlp.org/" rel="external nofollow noopener" target="_blank">EMNLP’23</a>). </span> </td> </tr> <tr> <th scope="row" style="width: 20%"><span style="color:black">2023 (Jun)</span></th> <td> <span style="color:black">🎓 Passed my candidacy and released <a href="https://yongzx.github.io/blog/posts/reflection-2year-PhD/">a blog post of my mid-PhD reflections</a>. </span> </td> </tr> <tr> <th scope="row" style="width: 20%"><span style="color:black">2023 (May)</span></th> <td> <span style="color:black">🎙️ <a href="https://www.wired.com/story/chatgpt-non-english-languages-ai-revolution/" rel="external nofollow noopener" target="_blank">Interviewed by Wired</a> on our <a href="https://arxiv.org/abs/2303.13592" rel="external nofollow noopener" target="_blank">code-switching paper</a> and grassroot research initiatve for Southeast Asian (SEA) languages. </span> </td> </tr> <tr> <th scope="row" style="width: 20%"><span style="color:black">2022 (Mar)</span></th> <td> <span style="color:black">🔥 <strong><a href="https://arxiv.org/abs/2110.08207" rel="external nofollow noopener" target="_blank">T0</a></strong> is accepted to ICLR’22 (Spotlight) and its <a href="https://bigscience.huggingface.co/blog/t0" rel="external nofollow noopener" target="_blank">blog post</a> is out! <strong><a href="https://arxiv.org/abs/2202.01279" rel="external nofollow noopener" target="_blank">PromptSource</a></strong> is also accepted to ACL’22 Demo track. </span> </td> </tr> <tr> <th scope="row" style="width: 20%"><span style="color:black">2021 (Jun)</span></th> <td> <span style="color:black">🎓 Started PhD at Brown University. </span> </td> </tr> </table> </div> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%63%6F%6E%74%61%63%74.%79%6F%6E%67@%62%72%6F%77%6E.%65%64%75" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=z6bOk-AAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://www.linkedin.com/in/yongzx" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://twitter.com/yong_zhengxin" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> <a href="https://yongzx.github.io/blog/" title="Blogger"><i class="fa-brands fa-blogger-b"></i></a> </div> <div class="contact-note">Most active on X (Twitter). Also feel free to email me. </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Yong Zheng-Xin. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Inspired by <a href="https://akariasai.github.io/" target="_blank" rel="external nofollow noopener">Akari Asai</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-K54RERLKHP"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-K54RERLKHP");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>