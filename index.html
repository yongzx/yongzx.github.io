<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="hFGM4TxPxthFmk31fTMEoGDKPU69WmAzgBZsOC0bzAk"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Yong Zheng-Xin </title> <meta name="author" content="Yong Zheng-Xin"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%91%A8%E2%80%8D%F0%9F%92%BB&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://yongzx.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%63%6F%6E%74%61%63%74.%79%6F%6E%67@%62%72%6F%77%6E.%65%64%75" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=z6bOk-AAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://twitter.com/yong_zhengxin" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item"><a class="nav-link" href="/assets/pdf/cv_yong.pdf">cv</a></li> <li class="nav-item"><a class="nav-link" href="https://yongzx.github.io/blog">blog</a></li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Yong</span> Zheng-Xin </h1> <p class="desc"><span style="color:grey">Computer Science Ph.D. student @ Brown University<br>Research Scientist Intern @ <a href="https://ai.meta.com/" style="color:#222222" rel="external nofollow noopener" target="_blank">Meta AI (FAIR)</a>, Collaborator @ <a href="https://cohere.com/research" style="color:#222222" rel="external nofollow noopener" target="_blank">Cohere For AI</a></span></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/prof_pic.jpg?a7550ca4e65c099866f3b23543cf5fc0" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic.jpg" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <p>I am a incoming fourth-year Ph.D. student in Computer Science at Brown University, advised by <a href="https://scholar.google.com/citations?user=hs6pGXoAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Prof. Stephen Bach</a>. I‚Äôm fortunate to have collaborated with amazing researchers at <a href="https://cohere.com/research" rel="external nofollow noopener" target="_blank">Cohere For AI</a> and at <a href="https://ai.meta.com/" rel="external nofollow noopener" target="_blank">Meta AI (FAIR and GenAI Team)</a>. <strong>Currently interning at Meta AI and will be back to Brown in Spring 2025.</strong></p> <p><strong>Lately, I focus on making multilingual LLMs safe</strong>, especially after I discovered that <a href="https://arxiv.org/abs/2310.02446" rel="external nofollow noopener" target="_blank"><span style="color:brown; font-weight:700;">low-resource languages can jailbreak GPT-4</span> (‚≠ëBest Paper Award, NeurIPS 2023 Socially Responsible Language Modeling Workshop)</a>. This work was highlighted in the <a href="https://www.gov.uk/government/publications/international-scientific-report-on-the-safety-of-advanced-ai" rel="external nofollow noopener" target="_blank">International Scientific Report on the Safety of Advanced AI 2024</a>, and it catalyzed the paradigm shift in industry AI labs towards multilingual red-teaming.</p> <p>My other notable contributions in AI safety includes:</p> <ul> <li>üîç I study why safety alignment works or fails in multilingual context (often with mechanistic interpretability). For instance, why toxicity reduction can generalize across languages <a href="https://arxiv.org/abs/2406.16235" rel="external nofollow noopener" target="_blank">(Findings of EMNLP 2024)</a> and why monolingual finetuning attacks can undo multilingual safety guardrails (<a href="https://arxiv.org/abs/2410.18210" rel="external nofollow noopener" target="_blank">preprint</a>).</li> <li>üåê I think about how the global open science community can contribute to AI safety research. For instance, I joined the advocate for <a href="https://arxiv.org/abs/2403.04893" rel="external nofollow noopener" target="_blank">A Safe Harbor for AI Evaluation and Red Teaming (ICML 2024)</a> (with an <a href="https://sites.mit.edu/ai-safe-harbor/" rel="external nofollow noopener" target="_blank">üìÑ open letter</a> signed by 300+ researchers and covered by <a href="https://www.washingtonpost.com/technology/2024/03/05/ai-research-letter-openai-meta-midjourney/" rel="external nofollow noopener" target="_blank">The Washington Post</a> and <a href="https://venturebeat.com/ai/experts-call-for-legal-safe-harbor-so-researchers-journalists-and-artists-can-evaluate-ai-tools/" rel="external nofollow noopener" target="_blank">VentureBeat</a>) to ensure legal and technical protections for AI red-teaming by independent researchers.</li> <li>üîì I have done safety red-teaming research in industry AI labs. <ul> <li> <strong><span style="color:brown;">Cohere For AI</span></strong>: I worked on red-teaming Aya-101 <a href="https://arxiv.org/abs/2402.07827" rel="external nofollow noopener" target="_blank">(‚≠ëBest Paper Award, ACL 2024)</a>.</li> <li> <strong><span style="color:brown;">Meta GenAI Trust (formerly Responsible AI)</span></strong>: I collaborated on a project of understanding finetuning attacks on multilingual LLMs such as Llama-3.1 and QWen-2 (<a href="https://arxiv.org/abs/2410.18210" rel="external nofollow noopener" target="_blank">preprint</a>).</li> </ul> </li> </ul> <p><strong>I also worked on making foundational models overcome language barriers</strong> so AI can serve all users around the world, including those who speak underrepresented languages. I have worked on both model-centric and data-centric solutions. I‚Äôve worked on adapting LLMs to low-resource languagesn <a href="https://arxiv.org/abs/2212.09535" rel="external nofollow noopener" target="_blank">(ACL 2023)</a> and generating synthetic data for low-resource languages <a href="https://arxiv.org/abs/2402.14086" rel="external nofollow noopener" target="_blank">(Findings of EMNLP 2024)</a>. I have also worked on massively multilingual LLMs and speech technology at following labs/groups:</p> <ul> <li> <strong>Meta FAIR</strong>: I worked on mitigating accent bias for the <a href="https://about.fb.com/news/2023/05/ai-massively-multilingual-speech-technology/" rel="external nofollow noopener" target="_blank">Massively Multilingual Speech model</a>.</li> <li> <strong>Cohere For AI</strong>: I served as a Malay language co-ambassador who coordinated the data collection efforts for Malay language in <a href="https://arxiv.org/abs/2402.06619" rel="external nofollow noopener" target="_blank">Aya dataset</a>.</li> <li> <strong>BigScience</strong>: I led language-modeling group to <a href="https://arxiv.org/abs/2212.09535" rel="external nofollow noopener" target="_blank">adapt BLOOM to unseen languages</a>. I also contributed to <a href="https://arxiv.org/abs/2110.08207" rel="external nofollow noopener" target="_blank">T0</a> (one of the earliest instruction-following LLM), <a href="https://arxiv.org/abs/2211.05100" rel="external nofollow noopener" target="_blank">BLOOM</a> (the world‚Äôs first largest open multilingual LLMs), and <a href="https://arxiv.org/abs/2211.01786" rel="external nofollow noopener" target="_blank">mT0/BLOOMZ</a> (the world‚Äôs first instruction-following multilingual LLM).</li> </ul> <p><strong>As a Malaysian, I also contributed to NLP for Southeast Asian (SEA) languages</strong>. I‚Äôve hosted <a href="https://aclanthology.org/2023.ijcnlp-tutorials.2/" rel="external nofollow noopener" target="_blank">*ACL tutorials</a>, helped curate SEACrowd data hub <a href="https://arxiv.org/abs/2406.10118" rel="external nofollow noopener" target="_blank">(EMNLP 2024)</a>, and studied how well LLMs can handle SEA linguistic phenomenon, such as code-switching <a href="https://arxiv.org/abs/2303.13592" rel="external nofollow noopener" target="_blank">(EMNLP 2023 CALCS Workshop)</a>, and understand culture in SEA region <a href="https://arxiv.org/abs/2406.05967" rel="external nofollow noopener" target="_blank">(NeurIPS 2024)</a>.</p> <p><strong>Other Misc Stuff:</strong></p> <ul> <li>If you want to chat or collaborate on any of the research directions above (or just talk about graduate schools), feel free to send an email to me: <code class="language-plaintext highlighter-rouge">contact [dot] yong @ brown [dot] edu</code>.</li> <li>My passion hobby is dancing, especially salsa and bachata. I also dance a bit of Lindy Hop, Argentine Tango and K-pop. <br>I usually check out the dance scenes in the city when I travel to conferences ‚Äì‚Äì‚Äì if you also enjoy dancing, hmu we can check them out together.</li> <li>I went to <a href="https://www.minerva.edu/" rel="external nofollow noopener" target="_blank">Minerva University</a> during undergrad so I had the opportunity to travel and live in six different cities around the world: üá∫üá∏ San Francisco, üá∞üá∑ Seoul, üáÆüá≥ Hyderabad, üá©üá™ Berlin, üá¶üá∑ Buenos Aires and üá¨üáß London.</li> </ul> </div> <hr> <h2> selected recent publications (<a href="/publications/" style="color: inherit">see all</a>) </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div id="li2024preference" class="col-sm-11"> <div class="title">Preference Tuning For Toxicity Mitigation Generalizes Across Languages</div> <div class="author"> Xiaochen Li* ,¬† <span style="font-weight:bold">Zheng-Xin Yong*</span> ,¬† and¬† Stephen H Bach </div> <div class="periodical"> <em>EMNLP Findings</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2406.16235" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/BatsResearch/cross-lingual-detox" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Detoxifying multilingual Large Language Models (LLMs) has become crucial due to their increasing global use. In this work, we explore zero-shot cross-lingual generalization of preference tuning in detoxifying LLMs. Unlike previous studies that show limited cross-lingual generalization for other safety tasks, we demonstrate that Direct Preference Optimization (DPO) training with only English data can significantly reduce toxicity in multilingual open-ended generations. For example, the probability of mGPT-1.3B generating toxic continuations drops from 46.8% to 3.9% across 17 different languages after training. Our results also extend to other multilingual LLMs, such as BLOOM, Llama3, and Aya-23. Using mechanistic interpretability tools like causal intervention and activation analysis, we identified the dual multilinguality property of MLP layers in LLMs, which explains the cross-lingual generalization of DPO. Finally, we show that bilingual sentence retrieval can predict the cross-lingual transferability of DPO preference tuning.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="ustun2024aya" class="col-sm-11"> <div class="title">Aya model: An instruction finetuned open-access multilingual language model</div> <div class="author"> Ahmet √úst√ºn* ,¬† Viraat Aryabumi* ,¬† <span style="font-weight:bold">Zheng-Xin Yong*</span> , and <span class="more-authors" title="click to view 14 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '14 more authors' ? 'Wei-Yin Ko*, Daniel D‚Äôsouza*, Gbemileke Onilude, Neel Bhandari, Shivalika Singh, Hui-Lee Ooi, Amr Kayid, Freddie Vargus, Phil Blunsom, Shayne Longpre, Niklas Muennighoff, Marzieh Fadaee, Julia Kreutzer, Sara Hooker' : '14 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">14 more authors</span> </div> <div class="periodical"> <em>ACL</em>, 2024 <span style="color:brown; font-weight:bold"> (Best Paper Award)</span> </div> <div class="periodical"> </div> <div> Also featured in: <a href="https://www.washingtonpost.com/politics/2024/02/13/ftcs-bedoya-says-laws-keep-teens-off-social-media-wont-work" rel="external nofollow noopener" target="_blank">The Washington Post</a> , <a href="https://www.theglobeandmail.com/business/article-ai-chatbots-fall-short-in-dozens-of-languages-a-non-profit-project" rel="external nofollow noopener" target="_blank">The Globe and Mail</a> , <a href="https://siliconangle.com/2024/02/13/cohere-ai-unveils-aya-multilingual-open-source-ai-101-languages/" rel="external nofollow noopener" target="_blank">SiliconANGLE</a>, etc. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2402.07827" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Recent breakthroughs in large language models (LLMs) have centered around a handful of data-rich languages. What does it take to broaden access to breakthroughs beyond first-class citizen languages? Our work introduces Aya, a massively multilingual generative language model that follows instructions in 101 languages of which over 50% are considered as lower-resourced. Aya outperforms mT0 and BLOOMZ on the majority of tasks while covering double the number of languages. We introduce extensive new evaluation suites that broaden the state-of-art for multilingual eval across 99 languages ‚Äì including discriminative and generative tasks, human evaluation, and simulated win rates that cover both held-out tasks and in-distribution performance. Furthermore, we conduct detailed investigations on the optimal finetuning mixture composition, data pruning, as well as the toxicity, bias, and safety of our models.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="yong2023lowresource" class="col-sm-11"> <div class="title">Low-Resource Languages Jailbreak GPT-4</div> <div class="author"> <span style="font-weight:bold">Zheng-Xin Yong</span> ,¬† Cristina Menghini ,¬† and¬† Stephen Bach </div> <div class="periodical"> <em>NeurIPS Workshop: Socially Responsible Language Modelling Research (SoLaR)</em> , 2023 <span style="color:brown; font-weight:bold"> (Best Paper Award)</span> </div> <div class="periodical"> </div> <div> Also featured in: <a href="https://www.newscientist.com/article/2398656-gpt-4-gave-advice-on-planning-terrorist-attacks-when-asked-in-zulu/" rel="external nofollow noopener" target="_blank">New Scientist</a> , <a href="https://hal.science/hal-04612963/document" rel="external nofollow noopener" target="_blank">UK AI Safety Institute (Scientific Report)</a> , <a href="https://www.zdnet.com/article/the-safety-of-openais-gpt-4-is-lost-in-translation/" rel="external nofollow noopener" target="_blank">ZDNet</a>, etc. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2310.02446" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>AI safety training and red-teaming of large language models (LLMs) are measures to mitigate the generation of unsafe content. Our work exposes the inherent cross-lingual vulnerability of these safety mechanisms, resulting from the linguistic inequality of safety training data, by successfully circumventing GPT-4‚Äôs safeguard through translating unsafe English inputs into low-resource languages. On the AdvBenchmark, GPT-4 engages with the unsafe translated inputs and provides actionable items that can get the users towards their harmful goals 79% of the time, which is on par with or even surpassing state-of-the-art jailbreaking attacks. Other high-/mid-resource languages have significantly lower attack success rate, which suggests that the cross-lingual vulnerability mainly applies to low-resource languages. Previously, limited training on low-resource languages primarily affects speakers of those languages, causing technological disparities. However, our work highlights a crucial shift: this deficiency now poses a risk to all LLMs users. Publicly available translation APIs enable anyone to exploit LLMs‚Äô safety vulnerabilities. Therefore, our work calls for a more holistic red-teaming efforts to develop robust multilingual safeguards with wide language coverage.</p> </div> </div> </div> </li> </ol> </div> <hr> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%"><span style="color:black">09 / 2024</span></th> <td> <span style="color:black"><a href="https://arxiv.org/abs/2402.14086" rel="external nofollow noopener" target="_blank">LexC-Gen</a> and <a href="https://arxiv.org/abs/2406.16235" rel="external nofollow noopener" target="_blank">mechanistic explanations of why removing toxicity generalizes across languages</a> were accepted to Findings of EMNLP 2024. <a href="https://arxiv.org/abs/2406.10118" rel="external nofollow noopener" target="_blank">SEACrowd</a> was also accepted to EMNLP 2024. <a href="https://arxiv.org/abs/2406.05967" rel="external nofollow noopener" target="_blank">CVQA</a> was accepted to NeurIPS 2024 Datasets &amp; Benchmarks. </span> </td> </tr> <tr> <th scope="row" style="width: 20%"><span style="color:black">08 / 2024</span></th> <td> <span style="color:black"><strong><a href="https://arxiv.org/abs/2402.07827" rel="external nofollow noopener" target="_blank"><span style="color:brown;">Aya Model paper</span></a></strong> received the <strong>‚≠ëBest Paper Award</strong> at ACL 2024. </span> </td> </tr> <tr> <th scope="row" style="width: 20%"><span style="color:black">07 / 2024</span></th> <td> <span style="color:black">Gave a talk about multilingual AI safety at <a href="https://lu.ma/fl2t9xms" rel="external nofollow noopener" target="_blank">London Data Week</a> (organized by The Alan Turing Institute and supported by Mayor of London). </span> </td> </tr> <tr> <th scope="row" style="width: 20%"><span style="color:black">06 / 2024</span></th> <td> <span style="color:black"><strong>Meta AI</strong>: Started my research scientist internship at Meta AI (FAIR), working on <a href="https://ai.meta.com/blog/multilingual-model-speech-recognition/" rel="external nofollow noopener" target="_blank">Massively Multilingual Speech (MMS)</a> models. Also collaborated with GenAI Trust Team on a multilingual safety project. </span> </td> </tr> <tr> <th scope="row" style="width: 20%"><span style="color:black">02 / 2024</span></th> <td> <span style="color:black"><a href="https://cohere.com/research/aya" rel="external nofollow noopener" target="_blank">Aya</a> model and dataset papers are released! I presented Aya multilingual safety research at Aya Grand Finale. </span> </td> </tr> <tr> <th scope="row" style="width: 20%"><span style="color:black">11 / 2023</span></th> <td> <span style="color:black">Co-organized the tutorial of <a href="https://aacl2023-sea-nlp.github.io/" rel="external nofollow noopener" target="_blank">Current Status of NLP in South East Asia</a> at AACL 2023. </span> </td> </tr> <tr> <th scope="row" style="width: 20%"><span style="color:black">10 / 2023</span></th> <td> <span style="color:black">‚Äú<strong><a href="https://arxiv.org/abs/2310.02446" rel="external nofollow noopener" target="_blank"><span style="color:brown;">Low-Resource Languages Jailbreak GPT-4</span></a></strong>‚Äù received the <strong>‚≠ëBest Paper Award</strong> at NeurIPS 2023 Socially Responsible Language Modeling (SoLaR) workshop. </span> </td> </tr> <tr> <th scope="row" style="width: 20%"><span style="color:black">09 / 2023</span></th> <td> <span style="color:black"><strong>Cohere For AI</strong>: Joining the Responsible Deployment Team for <a href="https://sites.google.com/cohere.com/aya-en/home" rel="external nofollow noopener" target="_blank">Aya</a> red-teaming. </span> </td> </tr> <tr> <th scope="row" style="width: 20%"><span style="color:black">05 / 2023</span></th> <td> <span style="color:black"><a href="https://www.wired.com/story/chatgpt-non-english-languages-ai-revolution/" rel="external nofollow noopener" target="_blank">Interviewed by Wired</a> on our <a href="https://arxiv.org/abs/2303.13592" rel="external nofollow noopener" target="_blank">code-switching paper</a> and grassroot research initiative for Southeast Asian (SEA) languages. </span> </td> </tr> <tr> <th scope="row" style="width: 20%"><span style="color:black">03 / 2022</span></th> <td> <span style="color:black"><a href="https://arxiv.org/abs/2110.08207" rel="external nofollow noopener" target="_blank">T0</a> is accepted to ICLR 2022 (Spotlight) and its <a href="https://bigscience.huggingface.co/blog/t0" rel="external nofollow noopener" target="_blank">blog post</a> is out! <a href="https://arxiv.org/abs/2202.01279" rel="external nofollow noopener" target="_blank">PromptSource</a> is also accepted to ACL 2022 Demo track. </span> </td> </tr> <tr> <th scope="row" style="width: 20%"><span style="color:black">06 / 2021</span></th> <td> <span style="color:black">Started PhD at Brown University. </span> </td> </tr> </table> </div> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%63%6F%6E%74%61%63%74.%79%6F%6E%67@%62%72%6F%77%6E.%65%64%75" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=z6bOk-AAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://twitter.com/yong_zhengxin" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <div class="contact-note">Most active on X (Twitter). Also feel free to email me. </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2024 Yong Zheng-Xin. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Inspired by <a href="https://akariasai.github.io/" target="_blank" rel="external nofollow noopener">Akari Asai</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-K54RERLKHP"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-K54RERLKHP");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>